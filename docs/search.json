[{"path":"https://andrew-mcinerney.github.io/statnn/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Andrew McInerney. Author, maintainer. Kevin Burke. Author.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McInerney , Burke K (2023). statnn: Statistically-Based Neural Networks. https://github.com/andrew-mcinerney/statnn, https://andrew-mcinerney.github.io/statnn/.","code":"@Manual{,   title = {statnn: Statistically-Based Neural Networks},   author = {Andrew McInerney and Kevin Burke},   year = {2023},   note = {https://github.com/andrew-mcinerney/statnn, https://andrew-mcinerney.github.io/statnn/}, }"},{"path":[]},{"path":"https://andrew-mcinerney.github.io/statnn/index.html","id":"casi-2023","dir":"","previous_headings":"","what":"CASI 2023","title":"Statistically-Based Neural Networks","text":"Check poster CASI 2023. can find GitHub repository poster .","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Statistically-Based Neural Networks","text":"can install development version statnn GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"andrew-mcinerney/statnn\")"},{"path":"https://andrew-mcinerney.github.io/statnn/index.html","id":"statnn","dir":"","previous_headings":"","what":"statnn()","title":"Statistically-Based Neural Networks","text":"primary function package statnn(). creates statistically-based object existing neural network object. Currently supports neural networks nnet, neuralnet, keras, ANN, torch. useful summary table can generated using covariate-effect plots can created using information functions arguments can found documentation.","code":"library(statnn) stnn <- statnn(object) summary(stnn) plot(stnn, conf_int = TRUE)"},{"path":"https://andrew-mcinerney.github.io/statnn/index.html","id":"notice","dir":"","previous_headings":"","what":"Notice","title":"Statistically-Based Neural Networks","text":"package currently development. experience issues, please get touch.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/Boston.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized Boston Housing Data — Boston","title":"Standardized Boston Housing Data — Boston","text":"data set containing housing values 506 suburbs Boston.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/Boston.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized Boston Housing Data — Boston","text":"","code":"Boston"},{"path":[]},{"path":"https://andrew-mcinerney.github.io/statnn/reference/Boston.html","id":"boston","dir":"Reference","previous_headings":"","what":"Boston","title":"Standardized Boston Housing Data — Boston","text":"data frame 506 rows 13 variables: crim per capita crime rate town. zn proportion residential land zoned lots 25,000 sq.ft. indus proportion non-retail business acres per town. chas Charles River dummy variable (= 1 tract bounds river; 0 otherwise). nox nitrogen oxides concentration (parts per 10 million). rm average number rooms per dwelling. age proportion owner-occupied units built prior 1940. dis weighted mean distances five Boston employment centres. rad index accessibility radial highways. tax full-value property-tax rate per $10,000. ptratio pupil-teacher ratio town. lstat lower status population (percent). medv median value owner-occupied homes $1000s.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/Boston.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Standardized Boston Housing Data — Boston","text":"dataset standardized version Boston dataset obtained ISLR2 library, orginally obtained slightly modified Boston dataset part MASS library. References available MASS library.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/Boston.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standardized Boston Housing Data — Boston","text":"James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) Introduction Statistical Learning applications R, https://www.statlearning.com, Springer-Verlag, New York","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/covariate_eff.html","id":null,"dir":"Reference","previous_headings":"","what":"Difference in average prediction for values above and below median — covariate_eff","title":"Difference in average prediction for values above and below median — covariate_eff","text":"Difference average prediction values median","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/covariate_eff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Difference in average prediction for values above and below median — covariate_eff","text":"","code":"covariate_eff(X, W, q, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/covariate_eff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Difference in average prediction for values above and below median — covariate_eff","text":"X Data W Weight vector q Number hidden units response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/covariate_eff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Difference in average prediction for values above and below median — covariate_eff","text":"Effect input","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/delta_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform delta method for a function FUN to calculate associated uncertainty — delta_method","title":"Perform delta method for a function FUN to calculate associated uncertainty — delta_method","text":"Perform delta method function FUN calculate associated uncertainty","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/delta_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform delta method for a function FUN to calculate associated uncertainty — delta_method","text":"","code":"delta_method(   W,   X,   y,   q,   ind,   FUN,   alpha = 0.05,   x_r = c(-3, 3),   len = 301,   lambda = 0,   response = \"continuous\",   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/delta_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform delta method for a function FUN to calculate associated uncertainty — delta_method","text":"W Weight vector X Data y Response q Number hidden units ind index column plot FUN function delta method alpha significance level x_r x-axis range len number breaks x-axis lambda Ridge penalty. Default 0. response Response type: \"continuous\" (default) \"binary\" ... additional arguments FUN","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/delta_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform delta method for a function FUN to calculate associated uncertainty — delta_method","text":"Effect input","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/hessian.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate hessian matrix — hessian","title":"Calculate hessian matrix — hessian","text":"Calculate hessian matrix","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/hessian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate hessian matrix — hessian","text":"","code":"hessian(W, X, y, q, lambda = 0, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/hessian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate hessian matrix — hessian","text":"W Weight vector X Data y Response q Number hidden units lambda Ridge penalty. Default 0. response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/hessian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate hessian matrix — hessian","text":"Hessian matrix","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/lr_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood ratio test for inputs — lr_test","title":"Likelihood ratio test for inputs — lr_test","text":"Likelihood ratio test inputs","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/lr_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood ratio test for inputs — lr_test","text":"","code":"lr_test(X, y, W, q, n_init = 1, unif = 3, maxit = 1000, ...)"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/lr_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood ratio test for inputs — lr_test","text":"X Data y Response W Weight vector q Number hidden nodes n_init Number initialisations unif Value generating random weights maxit Maximum number iterations nnet ... additional arguments nnet","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/lr_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood ratio test for inputs — lr_test","text":"Wald hypothesis test input","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/mlesim.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform m.l.e. simulation for a function FUN to calculate associated uncertainty — mlesim","title":"Perform m.l.e. simulation for a function FUN to calculate associated uncertainty — mlesim","text":"Perform m.l.e. simulation function FUN calculate associated uncertainty","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/mlesim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform m.l.e. simulation for a function FUN to calculate associated uncertainty — mlesim","text":"","code":"mlesim(   W,   X,   y,   q,   ind,   FUN,   B = 1000,   alpha = 0.05,   x_r = c(-3, 3),   len = 301,   lambda = 0,   response = \"continuous\",   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/mlesim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform m.l.e. simulation for a function FUN to calculate associated uncertainty — mlesim","text":"W Weight vector X Data y Response q Number hidden units ind index column plot FUN function m.l.e. simulation B number replicates alpha significance level x_r x-axis range len number breaks x-axis lambda Ridge penalty. Default 0. response Response type: \"continuous\" (default) \"binary\" ... additional arguments FUN","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/mlesim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform m.l.e. simulation for a function FUN to calculate associated uncertainty — mlesim","text":"Effect input","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nnet_to_torch.html","id":null,"dir":"Reference","previous_headings":"","what":"nnet weights to torch weights — nnet_to_torch","title":"nnet weights to torch weights — nnet_to_torch","text":"nnet weights torch weights","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nnet_to_torch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nnet weights to torch weights — nnet_to_torch","text":"","code":"nnet_to_torch(nnet_w, p, q)"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nnet_to_torch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nnet weights to torch weights — nnet_to_torch","text":"nnet_w weights nnet format p number inputs q number hidden nodes","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nnet_to_torch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nnet weights to torch weights — nnet_to_torch","text":"weights torch format","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits various tracks (different random starting values) and chooses best model — nn_fit","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"Fits n_init tracks different initial values decides best model based information criteria.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"","code":"nn_fit(...)  # S3 method for default nn_fit(   x,   y,   q,   n_init,   inf_crit = \"BIC\",   lambda = 0,   response = \"continuous\",   unif = 3,   maxit = 1000,   pkg = \"nnet\",   ... )  # S3 method for formula nn_fit(   formula,   data,   q,   n_init,   inf_crit = \"BIC\",   lambda = 0,   response = \"continuous\",   unif = 3,   maxit = 1000,   pkg = \"nnet\",   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"... additional argument nnet x Matrix covariates y Vector response q Number hidden nodes n_init Number random initialisations (tracks) inf_crit Information criterion: \"BIC\" (default), \"AIC\" \"AICc\" lambda Ridge penalty response Response type: \"continuous\" (default) \"binary\" unif Random initial values max value maxit Maximum number iterations nnet (default = 100) pkg Package fitting neural network. One nnet (default) torch formula object class \"formula\": two-sided object response left hand side model variables right hand side. data data frame containing variables model","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"best model different initialisations statnn object","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits various tracks (different random starting values) and chooses best model\r\nusing nnet — nn_fit_nnet","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing nnet — nn_fit_nnet","text":"Fits n_init tracks different initial values decides best model based information criteria.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_nnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing nnet — nn_fit_nnet","text":"","code":"nn_fit_nnet(   x,   y,   q,   n_init,   inf_crit = \"BIC\",   lambda = 0,   response = \"continuous\",   unif = 3,   maxit = 1000,   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_nnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing nnet — nn_fit_nnet","text":"x Matrix covariates y Vector response q Number hidden nodes n_init Number random initialisations (tracks) inf_crit Information criterion: \"BIC\" (default), \"AIC\" \"AICc\" lambda Ridge penalty response Response type: \"continuous\" (default) \"binary\" unif Random initial values max value maxit maximum number iterations nnet (default = 100) ... additional argument nnet","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_nnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing nnet — nn_fit_nnet","text":"best model different tracks","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_torch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits various tracks (different random starting values) and chooses best model\r\nusing torch — nn_fit_torch","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing torch — nn_fit_torch","text":"Fits n_init tracks different initial values decides best model based information criteria.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_torch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing torch — nn_fit_torch","text":"","code":"nn_fit_torch(   x,   y,   q,   n_init,   inf_crit = \"BIC\",   response = \"continuous\",   unif = 3,   maxit = 1000,   lambda = 0,   min_delta = 1e-08,   patience = 10,   batch_size = 32,   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_torch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing torch — nn_fit_torch","text":"x Matrix covariates y Vector response q Number hidden nodes n_init Number random initialisations (tracks) inf_crit Information criterion: \"BIC\" (default), \"AIC\" \"AICc\" response \"continuous\" (default) \"binary\" unif Random initial values max value maxit maximum number iterations nnet (default = 100) lambda ridge penalty min_delta tolerance early stopping patience patience ealy stopping batch_size batch size ... additional argument nnet","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_fit_torch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits various tracks (different random starting values) and chooses best model\r\nusing torch — nn_fit_torch","text":"best model different tracks","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loglike.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural Network Normal Log-likelihood Value — nn_loglike","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"Neural Network Normal Log-likelihood Value","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loglike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"","code":"nn_loglike(object, X = NULL, y = NULL, lambda = 0, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loglike.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"object neural network object X input data (required keras) y response variable (required keras) lambda Ridge penalty response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loglike.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"Log-Likelihood value","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural network loss — nn_loss","title":"Neural network loss — nn_loss","text":"Neural network loss","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural network loss — nn_loss","text":"","code":"nn_loss(W, X, y, q, lambda = 0, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural network loss — nn_loss","text":"W Weight vector X Data y Response variable q Number hidden nodes lambda Ridge peanlty response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural network loss — nn_loss","text":"loss given neural network","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural network prediction — nn_pred","title":"Neural network prediction — nn_pred","text":"Neural network prediction","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural network prediction — nn_pred","text":"","code":"nn_pred(X, W, q, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural network prediction — nn_pred","text":"X Data W Weight vector q Number hidden nodes response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/nn_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural network prediction — nn_pred","text":"Prediction given inputs","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pce.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial covariate effect — pce","title":"Partial covariate effect — pce","text":"Partial covariate effect","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pce.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial covariate effect — pce","text":"","code":"pce(W, X, q, ind, x_r = c(-3, 3), len = 301, d = \"sd\", response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pce.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial covariate effect — pce","text":"W Weight vector X Data q Number hidden units ind index column plot x_r x-axis range len number breaks x-axis d difference value response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pce.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial covariate effect — pce","text":"Effect input","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotci.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Wald Confidence Intervals — plotci","title":"Plot Wald Confidence Intervals — plotci","text":"plotci designed inspection confidence intervals weights objects class statnn.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Wald Confidence Intervals — plotci","text":"","code":"plotci(   object,   alpha = 0.05,   which = c(1L:object$n_inputs),   which_params = c(1L:object$n_nodes),   colour = 1,   ask = prod(graphics::par(\"mfcol\")) < length(which) && grDevices::dev.interactive(),   caption = lapply(1:ncol(object$X), function(iter) {          paste0(\"Confidence Intervals for \", colnames(object$X)[iter])  }),   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotci.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Wald Confidence Intervals — plotci","text":"object object class statnnet. alpha significane level. index plots displayed. which_params index weights displayed. colour colour confidence intervals. ask ask displaying plot. caption caption plot. ... arguments passed methods, graphical parameters (see par).","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotci.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Wald Confidence Intervals — plotci","text":"plot weights significance","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot neural network architecture — plotnn","title":"Plot neural network architecture — plotnn","text":"plotnn designed inspection weights objects class statnn.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot neural network architecture — plotnn","text":"","code":"plotnn(   x,   rep = NULL,   x.entry = NULL,   x.out = NULL,   radius = 0.15,   arrow.length = 0.2,   intercept = FALSE,   intercept.factor = 0.4,   information = FALSE,   information.pos = 0.1,   col.entry.synapse = \"black\",   col.entry = \"black\",   col.hidden = \"black\",   col.hidden.synapse = \"black\",   col.out = \"black\",   col.out.synapse = \"black\",   col.intercept = \"black\",   col.sig.synapse = \"black\",   col.insig.synapse = \"lightgrey\",   col.sig.node = \"black\",   col.insig.node = \"lightgrey\",   fontsize = 12,   dimension = 6,   show.weights = FALSE,   file = NULL,   rounding = 3,   alpha = 0.05,   lambda = 0,   ... )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot neural network architecture — plotnn","text":"x object class statnnet rep repetition neural network. rep=\"best\", repetition smallest error plotted. stated repetitions plotted, separate window. x.entry x-coordinate entry layer. Depends arrow.length default. x.x-coordinate output layer. radius radius neurons. arrow.length length entry arrows. intercept logical value indicating whether plot intercept. intercept.factor x-position factor intercept. closer factor 0, closer intercept left neuron. information logical value indicating whether add error steps plot. information.pos y-position information. col.entry.synapse color synapses leading input neurons. col.entry color input neurons. col.hidden color neurons hidden layer. col.hidden.synapse color weighted synapses. col.color output neurons. col..synapse color synapses leading away output neurons. col.intercept color intercept. col.sig.synapse color significant synapses. col.insig.synapse color insignificant synapses. col.sig.node color significant input nodes. col.insig.node color insignificant input nodes. fontsize fontsize text. dimension size plot inches. show.weights logical value indicating whether print calculated weights synapses. file character string naming plot write . stated, plot saved. rounding number decimal places round values. alpha significane level. lambda ridge penalty. ... arguments passed methods, graphical parameters (see par).","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/plotnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot neural network architecture — plotnn","text":"plot weights significance","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid activation function — sigmoid","title":"Sigmoid activation function — sigmoid","text":"Sigmoid activation function","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid activation function — sigmoid","text":"","code":"sigmoid(x)"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid activation function — sigmoid","text":"x Input","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid activation function — sigmoid","text":"Sigmoid function","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/statnn-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for Function statnn in Package statnn — statnn-methods","title":"Methods for Function statnn in Package statnn — statnn-methods","text":"Methods function statnn package statnn","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/statnn-methods.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Methods for Function statnn in Package statnn — statnn-methods","text":"signature(... = \"\")  signature(... = \"keras.engine.training.Model\")","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/statnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistically-Based Neural Networks — statnn","title":"Statistically-Based Neural Networks — statnn","text":"Return statistically-based outputs neural networks.","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/statnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistically-Based Neural Networks — statnn","text":"","code":"statnn(...)  statnn.default(object, B = 100, ...)  statnn.nnet(object, X, B = 100, ...)  statnn.keras.engine.training.Model(object, X, y, B = 100, ...)  statnn.nn(object, B = 100, ...)  statnn.ANN(object, X, B = 100, ...)  statnn.luz_module_fitted(object, X, y, B = 100, ...)"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/statnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistically-Based Neural Networks — statnn","text":"... arguments passed methods object nnet object B number bootstrap replicates X matrix input data y response variable","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/statnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistically-Based Neural Networks — statnn","text":"list information optimal model. statnn - object class statnn. statnn object statnn object statnn object statnn object statnn object statnn object statnn object","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/torch_to_nnet.html","id":null,"dir":"Reference","previous_headings":"","what":"torch weights to nnet weights — torch_to_nnet","title":"torch weights to nnet weights — torch_to_nnet","text":"torch weights nnet weights","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/torch_to_nnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"torch weights to nnet weights — torch_to_nnet","text":"","code":"torch_to_nnet(torch_w)"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/torch_to_nnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"torch weights to nnet weights — torch_to_nnet","text":"torch_w weights torch format","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/torch_to_nnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"torch weights to nnet weights — torch_to_nnet","text":"weights nnet format","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/VC.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate variance-covariance matrix — VC","title":"Calculate variance-covariance matrix — VC","text":"Calculate variance-covariance matrix","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/VC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate variance-covariance matrix — VC","text":"","code":"VC(W, X, y, q, lambda = 0, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/VC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate variance-covariance matrix — VC","text":"W Weight vector X Data y Response q Number hidden units lambda Ridge penalty. Default 0. response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/VC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate variance-covariance matrix — VC","text":"Hessian matrix","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_single_parameter.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald test for weights — wald_single_parameter","title":"Wald test for weights — wald_single_parameter","text":"Wald test weights","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_single_parameter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald test for weights — wald_single_parameter","text":"","code":"wald_single_parameter(   X,   y,   W,   q,   lambda = 0,   response = \"continuous\",   alpha = 0.05 )"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_single_parameter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald test for weights — wald_single_parameter","text":"X Data y Response W Weight vector q Number hidden nodes lambda Ridge penalty. Default 0. response Response type: \"continuous\" (default) \"binary\" alpha Significance level confidence interval","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_single_parameter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wald test for weights — wald_single_parameter","text":"Wald hypothesis test weight","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald test for inputs — wald_test","title":"Wald test for inputs — wald_test","text":"Wald test inputs","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald test for inputs — wald_test","text":"","code":"wald_test(X, y, W, q, lambda = 0, response = \"continuous\", alpha = 0.05)"},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald test for inputs — wald_test","text":"X Data y Response W Weight vector q Number hidden nodes lambda Ridge penalty. Default 0. response Response type: \"continuous\" (default) \"binary\" alpha significance level confidence interval","code":""},{"path":"https://andrew-mcinerney.github.io/statnn/reference/wald_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wald test for inputs — wald_test","text":"Wald hypothesis test input","code":""}]
