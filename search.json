[{"path":"https://andrew-mcinerney.github.io/interpretnn/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Andrew McInerney. Author, maintainer, copyright holder. Kevin Burke. Author.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McInerney , Burke K (2024). interpretnn: Interpreting Neural Networks Statistical Perspective. R package version 0.0.0.9000,  https://andrew-mcinerney.github.io/interpretnn/, https://github.com/andrew-mcinerney/interpretnn.","code":"@Manual{,   title = {interpretnn: Interpreting Neural Networks From a Statistical Perspective},   author = {Andrew McInerney and Kevin Burke},   year = {2024},   note = {R package version 0.0.0.9000,  https://andrew-mcinerney.github.io/interpretnn/},   url = {https://github.com/andrew-mcinerney/interpretnn}, }"},{"path":[]},{"path":"https://andrew-mcinerney.github.io/interpretnn/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Interpreting Neural Networks From a Statistical Perspective","text":"can install current version interpretnn CRAN : can install development version interpretnn GitHub :","code":"install.packages(\"interpretnn\") # install.packages(\"devtools\") devtools::install_github(\"andrew-mcinerney/interpretnn\")"},{"path":"https://andrew-mcinerney.github.io/interpretnn/index.html","id":"interpretnn","dir":"","previous_headings":"","what":"interpretnn()","title":"Interpreting Neural Networks From a Statistical Perspective","text":"primary function package interpretnn(). creates statistically-based object existing neural network object. Currently supports neural networks nnet, neuralnet, keras, ANN, torch. useful summary table can generated using covariate-effect plots can created using information functions arguments can found documentation.","code":"library(interpretnn) intnn <- interpretnn(object) summary(intnn) plot(intnn, conf_int = TRUE)"},{"path":"https://andrew-mcinerney.github.io/interpretnn/index.html","id":"notice","dir":"","previous_headings":"","what":"Notice","title":"Interpreting Neural Networks From a Statistical Perspective","text":"package currently development. experience issues, please get touch.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/Boston.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized Boston Housing Data — Boston","title":"Standardized Boston Housing Data — Boston","text":"data set containing housing values 506 suburbs Boston.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/Boston.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized Boston Housing Data — Boston","text":"","code":"Boston"},{"path":[]},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/Boston.html","id":"boston","dir":"Reference","previous_headings":"","what":"Boston","title":"Standardized Boston Housing Data — Boston","text":"data frame 506 rows 13 variables: crim per capita crime rate town. zn proportion residential land zoned lots 25,000 sq.ft. indus proportion non-retail business acres per town. chas Charles River dummy variable (= 1 tract bounds river; 0 otherwise). nox nitrogen oxides concentration (parts per 10 million). rm average number rooms per dwelling. age proportion owner-occupied units built prior 1940. dis weighted mean distances five Boston employment centres. rad index accessibility radial highways. tax full-value property-tax rate per $10,000. ptratio pupil-teacher ratio town. lstat lower status population (percent). medv median value owner-occupied homes $1000s.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/Boston.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Standardized Boston Housing Data — Boston","text":"dataset standardized version Boston dataset obtained ISLR2 library, orginally obtained slightly modified Boston dataset part MASS library. References available MASS library.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/Boston.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standardized Boston Housing Data — Boston","text":"James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) Introduction Statistical Learning applications R, https://www.statlearning.com, Springer-Verlag, New York","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/interpretnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistically-Based Neural Networks — interpretnn","title":"Statistically-Based Neural Networks — interpretnn","text":"Return statistically-based outputs neural networks.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/interpretnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistically-Based Neural Networks — interpretnn","text":"","code":"interpretnn(...)  interpretnn.default(object, ...)  interpretnn.nnet(object, X, ...)  interpretnn.keras.engine.training.Model(object, X, y, B = 100, ...)  interpretnn.nn(object, B = 100, ...)  interpretnn.ANN(object, X, y, B = 100, ...)  interpretnn.luz_module_fitted(object, X, y, B = 100, ...)  interpretnn.selectnn(object, B = 100, ...)"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/interpretnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistically-Based Neural Networks — interpretnn","text":"... arguments passed methods object selectnn object X matrix input data y response variable B number bootstrap replicates","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/interpretnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistically-Based Neural Networks — interpretnn","text":"list information optimal model. interpretnn - object class interpretnn. interpretnn object interpretnn object interpretnn object interpretnn object interpretnn object interpretnn object interpretnn object interpretnn object","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits various tracks (different random starting values) and chooses best model — nn_fit","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"Fits n_init tracks different initial values decides best model based information criteria.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"","code":"nn_fit(...)  # S3 method for default nn_fit(   x,   y,   q,   n_init,   inf_crit = \"BIC\",   lambda = 0,   response = \"continuous\",   unif = 3,   maxit = 1000,   pkg = \"nnet\",   ... )  # S3 method for formula nn_fit(   formula,   data,   q,   n_init,   inf_crit = \"BIC\",   lambda = 0,   response = \"continuous\",   unif = 3,   maxit = 1000,   pkg = \"nnet\",   ... )"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"... additional argument nnet x Matrix covariates y Vector response q Number hidden nodes n_init Number random initialisations (tracks) inf_crit Information criterion: \"BIC\" (default), \"AIC\" \"AICc\" lambda Ridge penalty response Response type: \"continuous\" (default) \"binary\" unif Random initial values max value maxit Maximum number iterations nnet (default = 100) pkg Package fitting neural network. One nnet (default) torch formula object class \"formula\": two-sided object response left hand side model variables right hand side. data data frame containing variables model","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits various tracks (different random starting values) and chooses best model — nn_fit","text":"best model different initialisations list estimates estimated standard errors. W_opt - vector optimal weights. value - value best information criterion. inf_crit_vec - value information criterion initialisation. convergence - value network convergence initialisation (1 maxmium iterations reached, 0 ). nn - optimal nnet object. interpretnn object","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural network gradient — nn_grad","title":"Neural network gradient — nn_grad","text":"Neural network gradient","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural network gradient — nn_grad","text":"","code":"nn_grad(W, X, q, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural network gradient — nn_grad","text":"W Weight vector X Input vector q Number hidden nodes response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_grad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural network gradient — nn_grad","text":"Log-Likelihood value","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loglike.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural Network Normal Log-likelihood Value — nn_loglike","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"Neural Network Normal Log-likelihood Value","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loglike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"","code":"nn_loglike(object, X = NULL, y = NULL, lambda = 0, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loglike.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"object neural network object X input data (required keras) y response variable (required keras) lambda Ridge penalty response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loglike.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural Network Normal Log-likelihood Value — nn_loglike","text":"Log-Likelihood value","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural network loss — nn_loss","title":"Neural network loss — nn_loss","text":"Neural network loss","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural network loss — nn_loss","text":"","code":"nn_loss(W, X, y, q, lambda = 0, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural network loss — nn_loss","text":"W Weight vector X Data y Response variable q Number hidden nodes lambda Ridge peanlty response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural network loss — nn_loss","text":"loss given neural network","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Neural network prediction — nn_pred","title":"Neural network prediction — nn_pred","text":"Neural network prediction","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neural network prediction — nn_pred","text":"","code":"nn_pred(X, W, q, response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neural network prediction — nn_pred","text":"X Data W Weight vector q Number hidden nodes response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/nn_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Neural network prediction — nn_pred","text":"Prediction given inputs","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pce.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial covariate effect — pce","title":"Partial covariate effect — pce","text":"Partial covariate effect","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pce.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial covariate effect — pce","text":"","code":"pce(W, X, q, ind, x_r = c(-3, 3), len = 101, d = \"sd\", response = \"continuous\")"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pce.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial covariate effect — pce","text":"W Weight vector X Data q Number hidden units ind index column plot x_r x-axis range len number breaks x-axis d difference value response Response type: \"continuous\" (default) \"binary\"","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pce.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial covariate effect — pce","text":"Effect input","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotci.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Wald Confidence Intervals — plotci","title":"Plot Wald Confidence Intervals — plotci","text":"plotci designed inspection confidence intervals weights objects class interpretnn.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotci.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Wald Confidence Intervals — plotci","text":"","code":"plotci(   object,   alpha = 0.05,   which = c(1L:object$n_inputs),   which_params = c(1L:object$n_nodes),   colour = 1,   ask = prod(graphics::par(\"mfcol\")) < length(which) && grDevices::dev.interactive(),   caption = lapply(1:ncol(object$X), function(iter) {          paste0(\"Confidence Intervals for \", colnames(object$X)[iter])  }),   ... )"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotci.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Wald Confidence Intervals — plotci","text":"object object class interpretnnet. alpha significane level. index plots displayed. which_params index weights displayed. colour colour confidence intervals. ask ask displaying plot. caption caption plot. ... arguments passed methods, graphical parameters (see par).","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotci.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Wald Confidence Intervals — plotci","text":"plot weights significance","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot neural network architecture — plotnn","title":"Plot neural network architecture — plotnn","text":"plotnn designed inspection weights objects class interpretnn.","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot neural network architecture — plotnn","text":"","code":"plotnn(   x,   rep = NULL,   x.entry = NULL,   x.out = NULL,   radius = 0.15,   arrow.length = 0.2,   intercept = FALSE,   intercept.factor = 0.4,   information = FALSE,   information.pos = 0.1,   col.entry.synapse = \"black\",   col.entry = \"black\",   col.hidden = \"black\",   col.hidden.synapse = \"black\",   col.out = \"black\",   col.out.synapse = \"black\",   col.intercept = \"black\",   col.sig.synapse = \"black\",   col.insig.synapse = \"lightgrey\",   col.sig.node = \"black\",   col.insig.node = \"lightgrey\",   fontsize = 12,   dimension = 6,   show.weights = FALSE,   file = NULL,   rounding = 3,   alpha = 0.05,   lambda = 0,   ... )"},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot neural network architecture — plotnn","text":"x object class interpretnnet rep repetition neural network. rep=\"best\", repetition smallest error plotted. stated repetitions plotted, separate window. x.entry x-coordinate entry layer. Depends arrow.length default. x.x-coordinate output layer. radius radius neurons. arrow.length length entry arrows. intercept logical value indicating whether plot intercept. intercept.factor x-position factor intercept. closer factor 0, closer intercept left neuron. information logical value indicating whether add error steps plot. information.pos y-position information. col.entry.synapse color synapses leading input neurons. col.entry color input neurons. col.hidden color neurons hidden layer. col.hidden.synapse color weighted synapses. col.color output neurons. col..synapse color synapses leading away output neurons. col.intercept color intercept. col.sig.synapse color significant synapses. col.insig.synapse color insignificant synapses. col.sig.node color significant input nodes. col.insig.node color insignificant input nodes. fontsize fontsize text. dimension size plot inches. show.weights logical value indicating whether print calculated weights synapses. file character string naming plot write . stated, plot saved. rounding number decimal places round values. alpha significane level. lambda ridge penalty. ... arguments passed methods, graphical parameters (see par).","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/plotnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot neural network architecture — plotnn","text":"plot weights significance","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/statnn-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for Function statnn in Package statnn — statnn-methods","title":"Methods for Function statnn in Package statnn — statnn-methods","text":"Methods function statnn package statnn","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/reference/statnn-methods.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Methods for Function statnn in Package statnn — statnn-methods","text":"signature(... = \"\")  signature(... = \"keras.engine.training.Model\")","code":""},{"path":"https://andrew-mcinerney.github.io/interpretnn/news/index.html","id":"interpretnn-development-version","dir":"Changelog","previous_headings":"","what":"interpretnn (development version)","title":"interpretnn (development version)","text":"Initial CRAN submission.","code":""}]
